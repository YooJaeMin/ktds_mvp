"""
RFP ë¶„ì„ í˜ì´ì§€
"""
import streamlit as st
import json
import time
from datetime import datetime
from docx import Document
import pandas as pd
import PyPDF2
import pdfplumber
import io

def show():
    """RFP ë¶„ì„ í˜ì´ì§€ í‘œì‹œ"""
    st.title("ğŸ” RFP ë¶„ì„")
    st.markdown("RFP ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•˜ê³  ë¶„ë¥˜í•©ë‹ˆë‹¤.")
    
    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    analysis_mode = st.radio(
        "ë¶„ì„ ëª¨ë“œ ì„ íƒ",
        ["ìƒˆ RFP ë¬¸ì„œ ë¶„ì„", "ì €ì¥ëœ RFP ì¬ë¶„ì„"],
        horizontal=True
    )
    
    if analysis_mode == "ìƒˆ RFP ë¬¸ì„œ ë¶„ì„":
        show_new_rfp_analysis()
    else:
        show_stored_rfp_analysis()

def show_new_rfp_analysis():
    """ìƒˆ RFP ë¬¸ì„œ ë¶„ì„"""
    st.subheader("ğŸ“„ ìƒˆ RFP ë¬¸ì„œ ë¶„ì„")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "RFP ë¬¸ì„œ ì—…ë¡œë“œ",
        type=['pdf', 'docx', 'txt'],
        help="ë¶„ì„í•  RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. PDF, DOCX, TXT í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )
    
    if uploaded_file:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.info(f"ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼: {uploaded_file.name} ({uploaded_file.size} bytes)")
        
        # ë¶„ì„ ì˜µì…˜
        st.subheader("ğŸ”§ ë¶„ì„ ì˜µì…˜")
        
        col1, col2 = st.columns(2)
        
        with col1:
            industry = st.selectbox(
                "ì—…ì¢…",
                ["ì€í–‰", "ë³´í—˜", "ì¦ê¶Œ", "ì¹´ë“œ", "ê¸°íƒ€"],
                help="RFPì˜ ëŒ€ìƒ ì—…ì¢…ì„ ì„ íƒí•˜ì„¸ìš”."
            )
            
            analysis_depth = st.selectbox(
                "ë¶„ì„ ê¹Šì´",
                ["ê¸°ë³¸", "ìƒì„¸", "ì‹¬í™”"],
                help="ë¶„ì„ì˜ ìƒì„¸ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”."
            )
        
        with col2:
            focus_area = st.multiselect(
                "ì¤‘ì  ë¶„ì„ ì˜ì—­",
                ["ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ê¸°ìˆ  ìŠ¤íƒ", "ë³´ì•ˆ ìš”êµ¬ì‚¬í•­", "ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­", "í†µí•© ìš”êµ¬ì‚¬í•­"],
                default=["ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­"],
                help="ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•  ì˜ì—­ì„ ì„ íƒí•˜ì„¸ìš”."
            )
        
        # ë¶„ì„ ì‹¤í–‰
        if st.button("ë¶„ì„ ì‹œì‘", type="primary"):
            if not focus_area:
                st.error("ìµœì†Œ í•˜ë‚˜ì˜ ì¤‘ì  ë¶„ì„ ì˜ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            with st.spinner("RFP ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                analyze_rfp_document(uploaded_file, industry, analysis_depth, focus_area)
            
            st.success("RFP ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

def show_stored_rfp_analysis():
    """ì €ì¥ëœ RFP ì¬ë¶„ì„"""
    st.subheader("ğŸ“ ì €ì¥ëœ RFP ì¬ë¶„ì„")
    
    try:
        azure_services = st.session_state.azure_services
        directories = azure_services.get_directories()
        
        if not directories:
            st.warning("ì €ì¥ëœ RFPê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € RFPë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.")
            return
        
        # ë””ë ‰í† ë¦¬ ëª©ë¡ì„ í…Œì´ë¸”ë¡œ í‘œì‹œ
        st.subheader("ğŸ“‹ ì €ì¥ëœ RFP ëª©ë¡")
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
        items_per_page = 10
        total_pages = (len(directories) + items_per_page - 1) // items_per_page
        
        if total_pages > 1:
            page = st.selectbox("í˜ì´ì§€ ì„ íƒ", range(1, total_pages + 1), key="rfp_page")
        else:
            page = 1
        
        start_idx = (page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        current_directories = directories[start_idx:end_idx]
        
        # í…Œì´ë¸” ë°ì´í„° ìƒì„± (ë””ë ‰í† ë¦¬ëª… ë° ì„ íƒ ì»¬ëŸ¼ ì œì™¸)
        table_data = []
        for i, directory in enumerate(current_directories):
            table_data.append({
                "í•œê¸€ëª…": directory['korean_name'],
                "ìƒì„±ì¼": directory['created_date'],
                "í”„ë¡œì íŠ¸ ìš”ì•½": directory['project_summary'][:50] + "..." if len(directory['project_summary']) > 50 else directory['project_summary']
            })
        
        # í…Œì´ë¸” í‘œì‹œ
        df = pd.DataFrame(table_data)
        st.dataframe(df, width='stretch')
        
        # ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ ì„ íƒ (í…Œì´ë¸”ê³¼ í•¨ê»˜ í‘œì‹œ)
        col1, col2 = st.columns([1, 3])
        with col1:
            st.markdown("**ì¬ë¶„ì„í•  RFP ì„ íƒ:**")
        with col2:
            selected_index = st.radio(
                "RFP ì„ íƒ",
                range(len(current_directories)),
                format_func=lambda x: f"{current_directories[x]['korean_name']}",
                horizontal=True,
                key="rfp_reanalysis_selection",
                label_visibility="collapsed"
            )
        
        if selected_index is not None:
            selected_directory = current_directories[selected_index]
            
            # íŒŒì¼ ëª©ë¡ í‘œì‹œ
            container_name = "rfp-documents"
            files = azure_services.list_files_in_directory(container_name, selected_directory['name'])
            if files:
                st.info(f"ğŸ“„ {selected_directory['korean_name']}ì— ì €ì¥ëœ íŒŒì¼: {', '.join(files)}")
                
                # ì¬ë¶„ì„ ì˜µì…˜
                st.subheader("ğŸ”„ ì¬ë¶„ì„ ì˜µì…˜")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    new_industry = st.selectbox(
                        "ì—…ì¢… (ë³€ê²½ ê°€ëŠ¥)",
                        ["ì€í–‰", "ë³´í—˜", "ì¦ê¶Œ", "ì¹´ë“œ", "ê¸°íƒ€"],
                        help="ì—…ì¢…ì„ ë³€ê²½í•˜ì—¬ ì¬ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                    
                    new_depth = st.selectbox(
                        "ë¶„ì„ ê¹Šì´ (ë³€ê²½ ê°€ëŠ¥)",
                        ["ê¸°ë³¸", "ìƒì„¸", "ì‹¬í™”"],
                        help="ë¶„ì„ ê¹Šì´ë¥¼ ë³€ê²½í•˜ì—¬ ì¬ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                
                with col2:
                    new_focus = st.multiselect(
                        "ì¤‘ì  ë¶„ì„ ì˜ì—­ (ë³€ê²½ ê°€ëŠ¥)",
                        ["ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ê¸°ìˆ  ìŠ¤íƒ", "ë³´ì•ˆ ìš”êµ¬ì‚¬í•­", "ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­", "í†µí•© ìš”êµ¬ì‚¬í•­"],
                        default=["ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­", "ë¹„ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­"],
                        help="ì¤‘ì  ë¶„ì„ ì˜ì—­ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                
                if st.button("ì¬ë¶„ì„ ì‹œì‘", type="primary"):
                    if not new_focus:
                        st.error("ìµœì†Œ í•˜ë‚˜ì˜ ì¤‘ì  ë¶„ì„ ì˜ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        return
                    
                    with st.spinner("ì €ì¥ëœ RFPë¥¼ ì¬ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        reanalyze_stored_rfp(selected_directory['name'], new_industry, new_depth, new_focus)
                    
                    st.success("RFP ì¬ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.warning("ì„ íƒëœ ë””ë ‰í† ë¦¬ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def analyze_rfp_document(uploaded_file, industry, analysis_depth, focus_area):
    """RFP ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰"""
    try:
        # ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ ì‹œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if hasattr(st.session_state, 'current_directory'):
            del st.session_state.current_directory
        if hasattr(st.session_state, 'current_container'):
            del st.session_state.current_container
        
        # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        st.info("ğŸ“„ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        content = extract_text_from_uploaded_file(uploaded_file)
        
        if not content:
            st.error("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        st.subheader("ğŸ“‹ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
        preview_length = 500
        if len(content) > preview_length:
            st.text_area("í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì)", content[:preview_length] + "...", height=200, disabled=True)
            st.info(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)}ì")
        else:
            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", content, height=200, disabled=True)
        
        # 1ë‹¨ê³„: RFP íŒŒì¼ì„ ë¨¼ì € Azure Storageì— ì—…ë¡œë“œ
        st.info("ğŸ“¤ RFP íŒŒì¼ì„ Azure Storageì— ì—…ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë¦¬ì…‹
        file_content = uploaded_file.read()
        
        # íŒŒì¼ í¬ê¸° ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
        st.info(f"ğŸ“Š ì›ë³¸ íŒŒì¼ í¬ê¸°: {len(file_content)} bytes, ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)}ì")
        
        # RFP íŒŒì¼ ì—…ë¡œë“œ (ë””ë ‰í† ë¦¬ ìƒì„± ë° ì„¸ì…˜ ìƒíƒœ ì„¤ì •)
        save_to_azure_storage(uploaded_file.name, file_content, analysis_depth, focus_area, extracted_text=content)
        
        # 2ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ìƒì„± (ê°™ì€ ë””ë ‰í† ë¦¬ì— ì €ì¥)
        st.info("ğŸ” í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        generate_analysis_results(content, industry, analysis_depth, focus_area, uploaded_file.name)
        
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def reanalyze_stored_rfp(directory_name, industry, analysis_depth, focus_area):
    """ì €ì¥ëœ RFP ì¬ë¶„ì„"""
    try:
        # ì¬ë¶„ì„ ì‹œì‘ ì‹œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if hasattr(st.session_state, 'current_directory'):
            del st.session_state.current_directory
        if hasattr(st.session_state, 'current_container'):
            del st.session_state.current_container
        
        azure_services = st.session_state.azure_services
        container_name = "rfp-documents"
        files = azure_services.list_files_in_directory(container_name, directory_name)
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ í•œê¸€ëª… ê°€ì ¸ì˜¤ê¸°
        metadata = azure_services.get_directory_metadata_from_path(container_name, directory_name)
        korean_name = metadata.get('korean_name', directory_name)
        
        ##ì‹œìŠ¤í…œ ì¶œë ¥
        st.info(f"ì¬ë¶„ì„í•  RFP: {korean_name}")
        if not files:
            st.error("ì¬ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # main_rfp_ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
        main_rfp_file = None
        for file_name in files:
            if file_name.startswith('main_rfp_'):
                main_rfp_file = file_name
                break
        
        if not main_rfp_file:
            st.error("main_rfp_ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        container_name = "rfp-documents"
        file_content = azure_services.download_file_from_directory(container_name, directory_name, main_rfp_file)
        
        if file_content:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ì„ íƒ
            if main_rfp_file.lower().endswith('.pdf'):
                # PDF íŒŒì¼ì˜ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
                content = extract_text_from_pdf_bytes(file_content)
            elif main_rfp_file.lower().endswith('.docx'):
                # DOCX íŒŒì¼ì˜ ê²½ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ ì‚¬ìš©
                content = extract_text_from_docx_bytes(file_content)
            elif main_rfp_file.lower().endswith('.txt'):
                # TXT íŒŒì¼ì˜ ê²½ìš° UTF-8 ë””ì½”ë”©
                content = file_content.decode('utf-8', errors='ignore')
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ UTF-8 ë””ì½”ë”© ì‹œë„
                content = file_content.decode('utf-8', errors='ignore')
            
            # ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ ìƒì„± (ì¬ë¶„ì„ ê²°ê³¼ìš©) - ì˜ì–´ì™€ ìˆ«ìë§Œ ì‚¬ìš©
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            new_directory_name = f"rfpreanalysis{timestamp}"
            
            # rfp-documents ì»¨í…Œì´ë„ˆ ë‚´ì— ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±
            container_name = "rfp-documents"
            
            # ì›ë³¸ RFP íŒŒì¼ì„ ìƒˆ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
            if azure_services.upload_file_to_directory(container_name, new_directory_name, main_rfp_file, file_content):
                # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.current_directory = new_directory_name
                st.session_state.current_container = container_name
                
                # ë¶„ì„ ê²°ê³¼ ìƒì„± ë° í‘œì‹œ (ìë™ ì €ì¥ ë¹„í™œì„±í™”)
                generate_analysis_results(content, industry, analysis_depth, focus_area, main_rfp_file, auto_save=False)
                
                # ì¬ë¶„ì„ ê²°ê³¼ë¥¼ ìƒˆ ë””ë ‰í† ë¦¬ì— ì €ì¥
                save_reanalysis_results(container_name, new_directory_name, content, industry, analysis_depth, focus_area)
                
                st.success(f"ì¬ë¶„ì„ ê²°ê³¼ê°€ ìƒˆ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {new_directory_name}")
            else:
                st.error("ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ì¬ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def save_reanalysis_results(container_name, directory_name, content, industry, analysis_depth, focus_area):
    """ì¬ë¶„ì„ ê²°ê³¼ë¥¼ ìƒˆ ë””ë ‰í† ë¦¬ì— ì €ì¥"""
    try:
        azure_services = st.session_state.azure_services
        
        # ì‹¤ì œ RFP ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ ìš”ì•½ ìƒì„±
        project_summary = generate_enhanced_project_summary(content, industry, analysis_depth, focus_area)
        korean_name = generate_korean_project_name(project_summary)
        
        # ì¬ë¶„ì„ ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'korean_name': f"{korean_name} (ì¬ë¶„ì„)",
            'created_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'project_summary': project_summary,
            'original_filename': "reanalysis_result",
            'analysis_depth': analysis_depth,
            'focus_areas': focus_area,
            'is_reanalysis': True
        }
        
        azure_services.save_directory_metadata_to_path(container_name, directory_name, metadata)
        
        # ì¬ë¶„ì„ ê²°ê³¼ DOCX íŒŒì¼ë“¤ ìƒì„± ë° ì €ì¥
        save_reanalysis_docx_files(container_name, directory_name, content, industry, analysis_depth, focus_area)
        
    except Exception as e:
        st.error(f"ì¬ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def save_reanalysis_docx_files(container_name, directory_name, content, industry, analysis_depth, focus_area):
    """ì¬ë¶„ì„ ê²°ê³¼ DOCX íŒŒì¼ë“¤ì„ ìƒì„±í•˜ê³  ì €ì¥"""
    try:
        azure_services = st.session_state.azure_services
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¶„ì„ ê²°ê³¼ ìƒì„±
        import concurrent.futures
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            # ëª¨ë“  ë¶„ì„ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            future_requirements = executor.submit(extract_requirements_with_azure, azure_services, content, industry, analysis_depth, focus_area)
            future_keywords = executor.submit(analyze_keywords_with_azure, azure_services, content, industry, analysis_depth)
            future_summary = executor.submit(generate_summary_report_with_azure, azure_services, content, industry, analysis_depth, focus_area)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            requirements = future_requirements.result()
            keywords = future_keywords.result()
            summary = future_summary.result()
        
        # í†µí•© ë¶„ì„ ê²°ê³¼ ìƒì„±
        combined_content = f"""
# RFP ì¬ë¶„ì„ ê²°ê³¼

## 1. ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
{requirements}

## 2. í‚¤ì›Œë“œ ë¶„ì„
{keywords}

## 3. ìš”ì•½ ë³´ê³ ì„œ
{summary}
        """
        
        # 1. ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥
        doc = Document()
        doc.add_heading('RFP ì¬ë¶„ì„ ê²°ê³¼', 0)
        doc.add_paragraph(combined_content)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_detailed = "temp_reanalysis_result_detail.docx"
        doc.save(temp_detailed)
        
        with open(temp_detailed, 'rb') as f:
            detailed_data = f.read()
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Azureì— ì—…ë¡œë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        detailed_filename = f"analysis_result_detail_{timestamp}.docx"
        azure_services.upload_file_to_directory(container_name, directory_name, detailed_filename, detailed_data)
        
        # 2. ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
        doc_summary = Document()
        doc_summary.add_heading('RFP ì¬ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ', 0)
        doc_summary.add_paragraph(summary)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_summary = "temp_reanalysis_result_summary.docx"
        doc_summary.save(temp_summary)
        
        with open(temp_summary, 'rb') as f:
            summary_data = f.read()
        
        # Azureì— ì—…ë¡œë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        summary_filename = f"analysis_result_summary_{timestamp}.docx"
        azure_services.upload_file_to_directory(container_name, directory_name, summary_filename, summary_data)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        import os
        os.remove(temp_detailed)
        os.remove(temp_summary)
        
        st.success("ğŸ“ ì¬ë¶„ì„ ê²°ê³¼ DOCX íŒŒì¼ë“¤ì´ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        st.error(f"ì¬ë¶„ì„ DOCX íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def generate_analysis_results(content, industry, analysis_depth, focus_area, file_name, auto_save=True):
    """ë¶„ì„ ê²°ê³¼ ìƒì„± ë° í‘œì‹œ"""
    try:
        azure_services = st.session_state.azure_services
        
        
        # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´ (íƒ­ ìœ„ìª½ì—)
        st.markdown("---")
        with st.container():
            st.markdown("### ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            st.info("ğŸ’¡ **ë¶„ì„ì´ ì™„ë£Œë˜ë©´ ì•„ë˜ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , í˜ì´ì§€ í•˜ë‹¨ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í†µí•´ ê²°ê³¼ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**")
        
        # íƒ­ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
        tab1, tab2, tab3 = st.tabs([
            "ğŸ“‹ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ", 
            "ğŸ” í‚¤ì›Œë“œ ë¶„ì„",
            "ğŸ“„ ìš”ì•½ ë³´ê³ ì„œ"
        ])
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ placeholder ìƒì„±
        with tab1:
            req_placeholder = st.empty()
            req_placeholder.info("ğŸ”„ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘...")
        
        with tab2:
            keyword_placeholder = st.empty()
            keyword_placeholder.info("ğŸ”„ í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...")
        
        with tab3:
            summary_placeholder = st.empty()
            summary_placeholder.info("ğŸ”„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # Azure ì„œë¹„ìŠ¤ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì™€ì„œ ë³‘ë ¬ ì²˜ë¦¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„
        azure_services = st.session_state.azure_services
        
        # ìµœì í™”ëœ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        from modules.performance import parallel_analysis_executor
        
        analyses = [
            {
                'name': 'requirements',
                'func': extract_requirements_with_azure,
                'args': (azure_services, content, industry, analysis_depth, focus_area),
                'kwargs': {}
            },
            {
                'name': 'keywords', 
                'func': analyze_keywords_with_azure,
                'args': (azure_services, content, industry, analysis_depth),
                'kwargs': {}
            },
            {
                'name': 'summary',
                'func': generate_summary_report_with_azure,
                'args': (azure_services, content, industry, analysis_depth, focus_area),
                'kwargs': {}
            }
        ]
        
        def run_analysis_with_azure(azure_services, content, industry, focus_area, analysis_depth):
            """ìµœì í™”ëœ Azure ì„œë¹„ìŠ¤ ë¶„ì„ ì‹¤í–‰"""
            results = parallel_analysis_executor(analyses, max_workers=3)
            
            # ê²°ê³¼ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í‘œì‹œ (ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ)
            # ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼ í‘œì‹œ
            requirements = results['requirements']
            req_placeholder.markdown(
                f"""
                <div style="max-height: 600px; overflow-y: auto; padding: 15px; border: 1px solid #e0e0e0; border-radius: 8px; background-color: #fafafa;">
                    {requirements}
                </div>
                """, 
                unsafe_allow_html=True
            )
            
            # í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            keywords = results['keywords']
            keyword_placeholder.markdown(
                f"""
                <div style="max-height: 600px; overflow-y: auto; padding: 15px; border: 1px solid #e0e0e0; border-radius: 8px; background-color: #fafafa;">
                    {keywords}
                </div>
                """, 
                unsafe_allow_html=True
            )
            create_keyword_cloud()
            
            # ìš”ì•½ ë³´ê³ ì„œ ê²°ê³¼ í‘œì‹œ
            summary = results['summary']
            summary_placeholder.markdown(
                f"""
                <div style="max-height: 600px; overflow-y: auto; padding: 15px; border: 1px solid #e0e0e0; border-radius: 8px; background-color: #fafafa;">
                    {summary}
                </div>
                """, 
                unsafe_allow_html=True
            )
            
            return results
        
        # ë¶„ì„ ì‹¤í–‰
        results = run_analysis_with_azure(azure_services, content, industry, focus_area, analysis_depth)
        requirements = results['requirements']
        keywords = results['keywords']
        summary = results['summary']
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë””ë ‰í† ë¦¬ì— ìë™ ì €ì¥ (auto_saveê°€ Trueì¼ ë•Œë§Œ)
        if auto_save:
            save_analysis_results_to_directory(content, industry, analysis_depth, focus_area, requirements, keywords, summary)
        
        # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        combined_content = f"""
# RFP ìƒì„¸ ë¶„ì„ ê²°ê³¼

## 1. ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼
{requirements}

## 2. í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
{keywords}
        """
        
        # íŒŒì¼ëª… ìƒì„±
        detailed_filename = "analysis_result_detail.docx"
        summary_filename = "analysis_result_summary.docx"
        
        # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
        st.session_state.requirements = requirements
        st.session_state.keywords = keywords
        st.session_state.summary = summary
        st.session_state.detailed_filename = detailed_filename
        st.session_state.summary_filename = summary_filename
        st.session_state.combined_content = combined_content
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ì„ íƒ­ ì•„ë˜ìª½ì— í‘œì‹œ
        st.markdown("---")
        
        # ì„±ê³µ ë©”ì‹œì§€ì™€ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ì„ ê°•ì¡°
        with st.container():
            st.success("ğŸ‰ **ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!** ì•„ë˜ ë²„íŠ¼ì„ í†µí•´ ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
            st.markdown("### ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ë‹¤ìš´ë¡œë“œ ë°ì´í„° ë¯¸ë¦¬ ìƒì„±
            detailed_filename = st.session_state.get('detailed_filename', 'analysis_result_detail.docx')
            detailed_download_data = create_download_data(detailed_filename, combined_content)
            
            # HTML ë‹¤ìš´ë¡œë“œ ë§í¬ ì‚¬ìš© (í˜ì´ì§€ ë¦¬ë¡œë“œ ë°©ì§€)
            detailed_link = create_download_link(detailed_download_data, detailed_filename, "ğŸ“„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (DOCX)")
            st.markdown(detailed_link, unsafe_allow_html=True)
        
        with col2:
            # ë‹¤ìš´ë¡œë“œ ë°ì´í„° ë¯¸ë¦¬ ìƒì„±
            summary_filename = st.session_state.get('summary_filename', 'analysis_result_summary.docx')
            summary_download_data = create_download_data(summary_filename, summary)
            
            # HTML ë‹¤ìš´ë¡œë“œ ë§í¬ ì‚¬ìš© (í˜ì´ì§€ ë¦¬ë¡œë“œ ë°©ì§€)
            summary_link = create_download_link(summary_download_data, summary_filename, "ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (DOCX)")
            st.markdown(summary_link, unsafe_allow_html=True)
                
    except Exception as e:
        st.error(f"ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

def extract_requirements(content, industry, analysis_depth, focus_area):
    """ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    azure_services = st.session_state.azure_services
    return extract_requirements_with_azure(azure_services, content, industry, analysis_depth, focus_area)

def extract_requirements_with_azure(azure_services, content, industry, analysis_depth, focus_area):
    """Azure ì„œë¹„ìŠ¤ë¥¼ ì „ë‹¬ë°›ì•„ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    
    # ë¶„ì„ ê¹Šì´ì— ë”°ë¥¸ ì§€ì‹œì‚¬í•­
    depth_instructions = {
        "ê¸°ë³¸": "ì£¼ìš” ìš”êµ¬ì‚¬í•­ ì´ 3ê°œë§Œ ê°„ëµí•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”. ê° í•­ëª©ë‹¹ 1-2ì¤„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.",
        "ìƒì„¸": "ëª¨ë“  ìš”êµ¬ì‚¬í•­ë³„ë¡œ 5ê°œë¥¼ ìƒì„¸í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”. ê° ìš”êµ¬ì‚¬í•­ì˜ ë°°ê²½ê³¼ ëª©ì ì„ í¬í•¨í•©ë‹ˆë‹¤.",
        "ì‹¬í™”": "ëª¨ë“  ìš”êµ¬ì‚¬í•­ë³„ë¡œ 10ê°œë¥¼ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì¶”ì¶œí•˜ê³ , ì ì¬ì  ì´ìŠˆ, êµ¬í˜„ ê³ ë ¤ì‚¬í•­, ê´€ë ¨ ìš”êµ¬ì‚¬í•­ê³¼ì˜ ì—°ê´€ì„±ê¹Œì§€ ë¶„ì„í•˜ì„¸ìš”."
    }
    
    messages = [
        {
            "role": "system",
            "content": f"ë‹¹ì‹ ì€ {industry} ì—…ì¢…ì˜ RFP ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. RFP ë¬¸ì„œì—ì„œ ìš”êµ¬ì‚¬í•­ì„ ì²´ê³„ì ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë¶„ì„ ê¹Šì´: {analysis_depth}"
        },
        {
            "role": "user",
            "content": f"""
            ì—…ì¢…: {industry}
            ë¶„ì„ ê¹Šì´: {analysis_depth}
            ì¤‘ì  ë¶„ì„ ì˜ì—­: {', '.join(focus_area)}
            
            ** ë¶„ì„ ì§€ì¹¨: {depth_instructions.get(analysis_depth, depth_instructions['ê¸°ë³¸'])} **
            
            RFP ë¬¸ì„œ ë‚´ìš©:
            {content}
            
            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•˜ê³ , **êµ¬ì²´ì ì¸ í‰ê°€ ì ìˆ˜ì™€ ê¸°ì¤€**ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”:
            
            ## ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼
            
            ### 1. ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
            - [ìš”êµ¬ì‚¬í•­ 1]: [ìƒì„¸ ì„¤ëª…]
              - ìš°ì„ ìˆœìœ„: [High/Medium/Low] (ì ìˆ˜: [N/10ì ])
              - êµ¬í˜„ ë‚œì´ë„: [ìƒ/ì¤‘/í•˜] (ì˜ˆìƒ ê³µìˆ˜: [N ì¸ì¼])
              - ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: [N/10ì ]
            {"  - êµ¬í˜„ ê³ ë ¤ì‚¬í•­: [ìƒì„¸ ì„¤ëª…]" if analysis_depth == "ì‹¬í™”" else ""}
            
            ### 2. ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
            - [ìš”êµ¬ì‚¬í•­ 1]: [ìƒì„¸ ì„¤ëª…]
              - ì¤‘ìš”ë„: [Critical/Important/Nice-to-have] (ì ìˆ˜: [N/10ì ])
              - ê¸°ìˆ ì  ë‚œì´ë„: [ìƒ/ì¤‘/í•˜]
              - ì„±ëŠ¥ ëª©í‘œ: [êµ¬ì²´ì  ìˆ˜ì¹˜, ì˜ˆ: ì‘ë‹µì‹œê°„ < 2ì´ˆ]
            {"  - ê¸°ìˆ ì  ì œì•½ì‚¬í•­: [ìƒì„¸ ì„¤ëª…]" if analysis_depth == "ì‹¬í™”" else ""}
            
            ### 3. ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­
            - [ìš”êµ¬ì‚¬í•­ 1]: [ìƒì„¸ ì„¤ëª…]
              - ë³µì¡ë„: [High/Medium/Low] (ì ìˆ˜: [N/10ì ])
              - ê¸°ìˆ  ì„±ìˆ™ë„: [ê²€ì¦ë¨/ë³´í†µ/ì‹ ê¸°ìˆ ]
              - ì˜ˆìƒ ë¦¬ìŠ¤í¬: [N/10ì ]
            {"  - ê¸°ìˆ  ìŠ¤íƒ ê¶Œì¥ì‚¬í•­: [ìƒì„¸ ì„¤ëª…]" if analysis_depth in ["ìƒì„¸", "ì‹¬í™”"] else ""}
            
            ### 4. ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­
            - [ìš”êµ¬ì‚¬í•­ 1]: [ìƒì„¸ ì„¤ëª…]
              - ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸: [High/Medium/Low] (ì ìˆ˜: [N/10ì ])
              - ê¸´ê¸‰ë„: [ì¦‰ì‹œ/ë‹¨ê¸°/ì¤‘ì¥ê¸°]
              - íˆ¬ì ëŒ€ë¹„ íš¨ê³¼: [N/10ì ]
            {"  - ROI ë¶„ì„: [ìƒì„¸ ì„¤ëª…]" if analysis_depth == "ì‹¬í™”" else ""}
            
            **í‰ê°€ ê¸°ì¤€:**
            - 10ì : í”„ë¡œì íŠ¸ í•„ìˆ˜ ìš”ì†Œ, ìµœìš°ì„  ì²˜ë¦¬
            - 8-9ì : í•µì‹¬ ìš”êµ¬ì‚¬í•­, ë†’ì€ ìš°ì„ ìˆœìœ„
            - 6-7ì : ì¤‘ìš” ìš”êµ¬ì‚¬í•­, ì¤‘ê°„ ìš°ì„ ìˆœìœ„
            - 4-5ì : ì¼ë°˜ ìš”êµ¬ì‚¬í•­, í•„ìš”ì‹œ ì¡°ì • ê°€ëŠ¥
            - 1-3ì : ì„ íƒì  ìš”êµ¬ì‚¬í•­, ì¶”ê°€ ê¸°ëŠ¥
            """
        }
    ]
    
    return azure_services.call_openai(messages)

def analyze_keywords(content, industry, analysis_depth):
    """í‚¤ì›Œë“œ ë¶„ì„"""
    azure_services = st.session_state.azure_services
    return analyze_keywords_with_azure(azure_services, content, industry, analysis_depth)

def analyze_keywords_with_azure(azure_services, content, industry, analysis_depth):
    """Azure ì„œë¹„ìŠ¤ë¥¼ ì „ë‹¬ë°›ì•„ í‚¤ì›Œë“œ ë¶„ì„"""
    
    # ë¶„ì„ ê¹Šì´ì— ë”°ë¥¸ í‚¤ì›Œë“œ ë¶„ì„ ë²”ìœ„
    depth_instructions = {
        "ê¸°ë³¸": "ìƒìœ„ 5ê°œ ì£¼ìš” í‚¤ì›Œë“œë§Œ ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.",
        "ìƒì„¸": "ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ê° í‚¤ì›Œë“œì˜ ë¬¸ë§¥ê³¼ ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”.",
        "ì‹¬í™”": "ìƒìœ„ 15ê°œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , í‚¤ì›Œë“œ ê°„ ì—°ê´€ì„±, íŠ¸ë Œë“œ ë¶„ì„, ì‚°ì—…ë³„ íŠ¹ì´ì‚¬í•­ê¹Œì§€ ìƒì„¸íˆ ë¶„ì„í•˜ì„¸ìš”."
    }
    
    messages = [
        {
            "role": "system",
            "content": f"ë‹¹ì‹ ì€ {industry} ì—…ì¢…ì˜ í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. RFP ë¬¸ì„œì˜ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ë¶„ì„ ê¹Šì´: {analysis_depth}"
        },
        {
            "role": "user",
            "content": f"""
            ì—…ì¢…: {industry}
            ë¶„ì„ ê¹Šì´: {analysis_depth}
            
            ** ë¶„ì„ ì§€ì¹¨: {depth_instructions.get(analysis_depth, depth_instructions['ê¸°ë³¸'])} **
            
            RFP ë¬¸ì„œ ë‚´ìš©:
            {content}
            
            ë‹¤ìŒ ê´€ì ì—ì„œ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ **êµ¬ì²´ì ì¸ ìˆ˜ì¹˜**ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
            
            ## í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
            
            ### 1. ê¸°ìˆ  í‚¤ì›Œë“œ
            - [í‚¤ì›Œë“œ 1]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            - [í‚¤ì›Œë“œ 2]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            {"- í‚¤ì›Œë“œ ì„¤ëª…: [ê¸°ìˆ ì  ì˜ë¯¸ ë° ì ìš© ì‚¬ë¡€]" if analysis_depth in ["ìƒì„¸", "ì‹¬í™”"] else ""}
            
            ### 2. ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ
            - [í‚¤ì›Œë“œ 1]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            - [í‚¤ì›Œë“œ 2]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            {"- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸: [ì˜ˆìƒ ì˜í–¥ë„]" if analysis_depth in ["ìƒì„¸", "ì‹¬í™”"] else ""}
            
            ### 3. ì—…ê³„ íŠ¹í™” í‚¤ì›Œë“œ
            - [í‚¤ì›Œë“œ 1]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            - [í‚¤ì›Œë“œ 2]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            {f"- {industry} ì—…ì¢… íŠ¹ì„±: [ìƒì„¸ ì„¤ëª…]" if analysis_depth in ["ìƒì„¸", "ì‹¬í™”"] else ""}
            
            ### 4. íŠ¸ë Œë“œ í‚¤ì›Œë“œ
            - [í‚¤ì›Œë“œ 1]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            - [í‚¤ì›Œë“œ 2]: ì¶œí˜„ ë¹ˆë„ [NíšŒ], ì¤‘ìš”ë„ [N/10ì ], ë¬¸ì„œ ë‚´ ë¹„ì¤‘ [N%]
            {"- ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„: [ì‚°ì—… ë™í–¥ê³¼ì˜ ì—°ê´€ì„±]" if analysis_depth == "ì‹¬í™”" else ""}
            
            **ì¤‘ìš”ë„ í‰ê°€ ê¸°ì¤€:**
            - 10ì : í”„ë¡œì íŠ¸ ì„±ê³µì˜ í•µì‹¬ ìš”ì†Œ
            - 8-9ì : ë§¤ìš° ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­
            - 6-7ì : ì¤‘ìš”í•œ ê³ ë ¤ì‚¬í•­
            - 4-5ì : ë³´í†µ ìˆ˜ì¤€ì˜ ì¤‘ìš”ë„
            - 1-3ì : ì°¸ê³  ìˆ˜ì¤€
            
            {"### 5. í‚¤ì›Œë“œ ì—°ê´€ì„± ë¶„ì„\n- ì£¼ìš” í‚¤ì›Œë“œ ê°„ ê´€ê³„ ë§µ\n- í‚¤ì›Œë“œ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼" if analysis_depth == "ì‹¬í™”" else ""}
            """
        }
    ]
    
    return azure_services.call_openai(messages)


def generate_summary_report(content, industry, analysis_depth, focus_area):
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    azure_services = st.session_state.azure_services
    return generate_summary_report_with_azure(azure_services, content, industry, analysis_depth, focus_area)

def generate_summary_report_with_azure(azure_services, content, industry, analysis_depth, focus_area):
    """Azure ì„œë¹„ìŠ¤ë¥¼ ì „ë‹¬ë°›ì•„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    
    messages = [
        {
            "role": "system",
            "content": f"ë‹¹ì‹ ì€ {industry} ì—…ì¢…ì˜ RFP ë¶„ì„ ë³´ê³ ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¢…í•©ì ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
        },
        {
            "role": "user",
            "content": f"""
            ì—…ì¢…: {industry}
            ë¶„ì„ ê¹Šì´: {analysis_depth}
            ì¤‘ì  ì˜ì—­: {', '.join(focus_area)}
            
            RFP ë¬¸ì„œ ë‚´ìš©:
            {content}
            
            ë‹¤ìŒ êµ¬ì¡°ë¡œ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ## RFP ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ
            
            ### 1. Executive Summary
            - í”„ë¡œì íŠ¸ ê°œìš”
            - ì£¼ìš” ìš”êµ¬ì‚¬í•­ ìš”ì•½
            - ì˜ˆìƒ ë³µì¡ë„ ë° ë¦¬ìŠ¤í¬
            
            ### 2. í•µì‹¬ ìš”êµ¬ì‚¬í•­ ë¶„ì„
            - Critical ìš”êµ¬ì‚¬í•­
            - High Priority ìš”êµ¬ì‚¬í•­
            - ê¸°ìˆ ì  ë„ì „ ìš”ì†Œ
            
            ### 3. ì—…ì¢…ë³„ íŠ¹í™” ë¶„ì„
            - {industry} ì—…ì¢… íŠ¹ì„± ë°˜ì˜
            - ê·œì œ ìš”êµ¬ì‚¬í•­
            - ê²½ìŸì‚¬ ë²¤ì¹˜ë§ˆí‚¹
            
            ### 4. ì œì•ˆ ì „ëµ ê°€ì´ë“œ
            - ê°•ì  í™œìš© ë°©ì•ˆ
            - ì•½ì  ë³´ì™„ ì „ëµ
            - ì°¨ë³„í™” í¬ì¸íŠ¸
            
            ### 5. ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­
            - ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ í•„ìš”ì‚¬í•­
            - ì œì•ˆì„œ ì‘ì„± ìš°ì„ ìˆœìœ„
            - ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆ
            """
        }
    ]
    
    return azure_services.call_openai(messages)

def create_keyword_cloud():
    """í‚¤ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± (ìƒ˜í”Œ)"""
    st.subheader("ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„")
    
    # ìƒ˜í”Œ í‚¤ì›Œë“œ ë°ì´í„°
    keywords_data = {
        "í‚¤ì›Œë“œ": ["ë””ì§€í„¸ì „í™˜", "í´ë¼ìš°ë“œ", "API", "ë³´ì•ˆ", "ì„±ëŠ¥", "í†µí•©", "ì‚¬ìš©ìê²½í—˜", "ë°ì´í„°ë¶„ì„"],
        "ë¹ˆë„": [15, 12, 10, 9, 8, 7, 6, 5],
        "ì¤‘ìš”ë„": ["High", "High", "Medium", "High", "Medium", "Medium", "Medium", "Low"]
    }
    
    df = pd.DataFrame(keywords_data)
    st.dataframe(df, use_container_width=True)

def save_to_azure_storage(file_name, file_content, analysis_depth, focus_area, extracted_text=None):
    """Azure Storageì— ì €ì¥"""
    try:
        azure_services = st.session_state.azure_services
        
        # ë””ë ‰í† ë¦¬ëª… ìƒì„± (rfp{timestamp}) - ì˜ì–´ì™€ ìˆ«ìë§Œ ì‚¬ìš©
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        directory_name = f"rfp{timestamp}"
        
        # RFP íŒŒì¼ëª…ì„ main_rfp_ ì ‘ë‘ì‚¬ë¡œ ë³€ê²½
        main_rfp_name = f"main_rfp_{file_name}"
        
        # rfp-documents ì»¨í…Œì´ë„ˆ ë‚´ì— ë””ë ‰í† ë¦¬ ìƒì„±
        container_name = "rfp-documents"
        
        # RFP íŒŒì¼ ì—…ë¡œë“œ (ë””ë²„ê¹… ì •ë³´ ì¶”ê°€)
        st.info(f"ğŸ“¤ Azure Storageì— ì—…ë¡œë“œ ì¤‘... íŒŒì¼ëª…: {main_rfp_name}, í¬ê¸°: {len(file_content)} bytes")
        upload_success = azure_services.upload_file_to_directory(container_name, directory_name, main_rfp_name, file_content)
        
        if upload_success:
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë³„ë„ë¡œ ì €ì¥
            if extracted_text:
                extracted_text_name = f"extracted_text_{file_name}.txt"
                azure_services.upload_file_to_directory(
                    container_name, 
                    directory_name, 
                    extracted_text_name, 
                    extracted_text.encode('utf-8')
                )
            
            # í”„ë¡œì íŠ¸ëª… í•œê¸€ ìš”ì•½ ë©”íƒ€ë°ì´í„° ìƒì„± (ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìš°ì„  ì‚¬ìš©)
            content_for_summary = extracted_text if extracted_text else file_content
            project_summary = generate_project_summary(content_for_summary, analysis_depth, focus_area)
            korean_name = generate_korean_project_name(project_summary)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                'korean_name': korean_name,
                'created_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'project_summary': project_summary,
                'original_filename': file_name,
                'analysis_depth': analysis_depth,
                'focus_areas': focus_area
            }
            
            if azure_services.save_directory_metadata_to_path(container_name, directory_name, metadata):
                # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.current_directory = directory_name
                st.session_state.current_container = container_name
                st.success(f"ğŸ“ RFPê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {korean_name} ({directory_name})")
            else:
                st.warning("ë©”íƒ€ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error(f"âŒ íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í¬ê¸°: {len(file_content)} bytes")
            
    except Exception as e:
        st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def generate_project_summary(file_content, analysis_depth, focus_area):
    """í”„ë¡œì íŠ¸ëª… í•œê¸€ ìš”ì•½ ìƒì„±"""
    try:
        azure_services = st.session_state.azure_services
        
        # íŒŒì¼ ë‚´ìš©ì´ ë°”ì´íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(file_content, bytes):
            try:
                content_text = file_content.decode('utf-8', errors='ignore')
            except:
                content_text = str(file_content)
        else:
            content_text = str(file_content)
        
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ RFP ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. RFP ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì„ í•œê¸€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."
            },
            {
                "role": "user",
                "content": f"""
                RFP ë‚´ìš©: {content_text[:2000]}...
                ë¶„ì„ ê¹Šì´: {analysis_depth}
                ì¤‘ì  ì˜ì—­: {', '.join(focus_area)}
                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ í•œê¸€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
                
                ## í”„ë¡œì íŠ¸ ìš”ì•½
                - í”„ë¡œì íŠ¸ëª…: [í•œê¸€ í”„ë¡œì íŠ¸ëª…]
                - í•µì‹¬ ëª©í‘œ: [í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ëª©í‘œ]
                - ì£¼ìš” ê¸°ëŠ¥: [ì£¼ìš” ê¸°ëŠ¥ 3-5ê°œ]
                - ê¸°ìˆ  ìŠ¤íƒ: [ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ]
                - ì˜ˆìƒ ê·œëª¨: [ì†Œê·œëª¨/ì¤‘ê·œëª¨/ëŒ€ê·œëª¨]
                """
            }
        ]
        
        return azure_services.call_openai(messages)
    except Exception as e:
        return f"í”„ë¡œì íŠ¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

def generate_enhanced_project_summary(content, industry, analysis_depth, focus_area):
    """ì¬ë¶„ì„ìš© í–¥ìƒëœ í”„ë¡œì íŠ¸ ìš”ì•½ ìƒì„±"""
    try:
        azure_services = st.session_state.azure_services
        
        # íŒŒì¼ ë‚´ìš©ì´ ë°”ì´íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(content, bytes):
            try:
                content_text = content.decode('utf-8', errors='ignore')
            except:
                content_text = str(content)
        else:
            content_text = str(content)
        
        messages = [
            {
                "role": "system",
                "content": f"""ë‹¹ì‹ ì€ {industry} ì—…ì¢…ì˜ RFP ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                RFP ë‚´ìš©ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  í•œê¸€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
                ì‹¤ì œ RFP ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."""
            },
            {
                "role": "user",
                "content": f"""
                ì—…ì¢…: {industry}
                RFP ë‚´ìš©: {content_text[:3000]}...
                ë¶„ì„ ê¹Šì´: {analysis_depth}
                ì¤‘ì  ì˜ì—­: {', '.join(focus_area)}
                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì •í™•íˆ í•œê¸€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
                
                ## í”„ë¡œì íŠ¸ ìš”ì•½
                - í”„ë¡œì íŠ¸ëª…: [RFPì—ì„œ ì¶”ì¶œí•œ ì‹¤ì œ í”„ë¡œì íŠ¸ëª…]
                - í•µì‹¬ ëª©í‘œ: [RFPì—ì„œ ëª…ì‹œëœ êµ¬ì²´ì ì¸ ëª©í‘œ]
                - ì£¼ìš” ê¸°ëŠ¥: [RFPì—ì„œ ìš”êµ¬í•˜ëŠ” ì£¼ìš” ê¸°ëŠ¥ë“¤]
                - ê¸°ìˆ  ìŠ¤íƒ: [RFPì—ì„œ ìš”êµ¬í•˜ëŠ” ê¸°ìˆ  ìŠ¤íƒ]
                - ì˜ˆìƒ ê·œëª¨: [RFP ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•œ ê·œëª¨]
                - ì˜ˆì‚° ê·œëª¨: [RFPì—ì„œ ì–¸ê¸‰ëœ ì˜ˆì‚° ì •ë³´]
                - ë‚©ê¸°ì¼: [RFPì—ì„œ ëª…ì‹œëœ ì¼ì •]
                - ì£¼ìš” ìš”êµ¬ì‚¬í•­: [RFPì˜ í•µì‹¬ ìš”êµ¬ì‚¬í•­ 3-5ê°œ]
                """
            }
        ]
        
        return azure_services.call_openai(messages)
    except Exception as e:
        return f"í–¥ìƒëœ í”„ë¡œì íŠ¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

def generate_korean_project_name(project_summary):
    """í”„ë¡œì íŠ¸ í•œê¸€ëª… ìƒì„±"""
    try:
        azure_services = st.session_state.azure_services
        
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ëª… ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•œ í•œê¸€ í”„ë¡œì íŠ¸ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
            },
            {
                "role": "user",
                "content": f"""
                í”„ë¡œì íŠ¸ ìš”ì•½:
                {project_summary}
                
                ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í•œê¸€ í”„ë¡œì íŠ¸ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
                - 10-20ì ì´ë‚´
                - í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì„ ì˜ í‘œí˜„
                - ì´í•´í•˜ê¸° ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©
                - ê¸ˆìœµ/IT ì—…ê³„ì— ì í•©í•œ í‘œí˜„
                
                í”„ë¡œì íŠ¸ëª…ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš” (ì„¤ëª… ì—†ì´).
                """
            }
        ]
        
        korean_name = azure_services.call_openai(messages)
        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        korean_name = korean_name.strip().replace('í”„ë¡œì íŠ¸ëª…:', '').replace('**', '').strip()
        return korean_name[:20]  # ìµœëŒ€ 20ìë¡œ ì œí•œ
    except Exception as e:
        return f"í”„ë¡œì íŠ¸ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

def save_analysis_results_to_directory(content, industry, analysis_depth, focus_area, requirements, keywords, summary):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë””ë ‰í† ë¦¬ì— ìë™ ì €ì¥"""
    try:
        azure_services = st.session_state.azure_services
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        if not hasattr(st.session_state, 'current_directory') or not st.session_state.current_directory:
            # ë””ë ‰í† ë¦¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            directory_name = f"rfp{timestamp}"
            container_name = "rfp-documents"
            
            # ì„¸ì…˜ ìƒíƒœì— ë””ë ‰í† ë¦¬ ì •ë³´ ì €ì¥
            st.session_state.current_directory = directory_name
            st.session_state.current_container = container_name
            
            st.info(f"ğŸ“ ìƒˆ ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {directory_name}")
        else:
            # ì´ë¯¸ ë””ë ‰í† ë¦¬ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ê·¸ ë””ë ‰í† ë¦¬ ì‚¬ìš©
            container_name = st.session_state.current_container
            directory_name = st.session_state.current_directory
            st.info(f"ğŸ“ ê¸°ì¡´ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {directory_name}")
        
        # 1. ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥
        detailed_content = f"""
# RFP ìƒì„¸ ë¶„ì„ ê²°ê³¼

## 1. ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ê²°ê³¼
{requirements}

## 2. í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
{keywords}
        """
        
        # Word ë¬¸ì„œ ìƒì„± ë° ì €ì¥
        doc = Document()
        doc.add_heading('RFP ìƒì„¸ ë¶„ì„ ê²°ê³¼', 0)
        doc.add_paragraph(detailed_content)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_detailed = "temp_analysis_result_detail.docx"
        doc.save(temp_detailed)
        
        with open(temp_detailed, 'rb') as f:
            detailed_data = f.read()
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Azureì— ì—…ë¡œë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        detailed_filename = f"analysis_result_detail_{timestamp}.docx"
        azure_services.upload_file_to_directory(container_name, directory_name, detailed_filename, detailed_data)
        
        # 2. ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
        doc_summary = Document()
        doc_summary.add_heading('RFP ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ', 0)
        doc_summary.add_paragraph(summary)
        
        temp_summary = "temp_analysis_result_summary.docx"
        doc_summary.save(temp_summary)
        
        with open(temp_summary, 'rb') as f:
            summary_data = f.read()
        
        # Azureì— ì—…ë¡œë“œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        summary_filename = f"analysis_result_summary_{timestamp}.docx"
        azure_services.upload_file_to_directory(container_name, directory_name, summary_filename, summary_data)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        import os
        os.remove(temp_detailed)
        os.remove(temp_summary)
        
        st.success("ğŸ“ ë¶„ì„ ê²°ê³¼ê°€ ë””ë ‰í† ë¦¬ì— ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        st.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        st.error("ğŸ’¡ **í•´ê²° ë°©ë²•:** í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")

def create_download_data(filename, content):
    """ë‹¤ìš´ë¡œë“œìš© ë°ì´í„° ìƒì„±"""
    try:
        # Word ë¬¸ì„œ ìƒì„±
        doc = Document()
        doc.add_heading('RFP ë¶„ì„ ê²°ê³¼', 0)
        doc.add_paragraph(content)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_filename = f"temp_{filename}"
        doc.save(temp_filename)
        
        # íŒŒì¼ ì½ê¸°
        with open(temp_filename, 'rb') as f:
            file_data = f.read()
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        import os
        os.remove(temp_filename)
        
        return file_data
        
    except Exception as e:
        st.error(f"ë‹¤ìš´ë¡œë“œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return b""

def create_download_link(data, filename, label):
    """ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± (í˜ì´ì§€ ë¦¬ë¡œë“œ ë°©ì§€)"""
    import base64
    import io
    
    # ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
    b64 = base64.b64encode(data).decode()
    
    # HTML ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{filename}" style="display: inline-block; padding: 0.5rem 1rem; background-color: #1f77b4; color: white; text-decoration: none; border-radius: 0.25rem; border: none; cursor: pointer;">{label}</a>'
    
    return href

def download_analysis_result(filename, content):
    """ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    try:
        # Word ë¬¸ì„œ ìƒì„±
        doc = Document()
        doc.add_heading('RFP ë¶„ì„ ê²°ê³¼', 0)
        doc.add_paragraph(content)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_filename = f"temp_{filename}"
        doc.save(temp_filename)
        
        # íŒŒì¼ ì½ê¸°
        with open(temp_filename, 'rb') as f:
            file_data = f.read()
        
        # ë‹¤ìš´ë¡œë“œ ì œê³µ
        st.download_button(
            label=f"{filename} ë‹¤ìš´ë¡œë“œ",
            data=file_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        import os
        os.remove(temp_filename)
        
    except Exception as e:
        st.error(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def extract_text_from_pdf(uploaded_file):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸°
        file_bytes = uploaded_file.read()
        return extract_text_from_pdf_bytes(file_bytes)
        
    except Exception as e:
        st.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_from_pdf_bytes(file_bytes):
    """PDF ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # pdfplumberë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë” ì •í™•í•¨)
        text_content = ""
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text_content += page_text + "\n"
        
        # pdfplumberë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•œ ê²½ìš° PyPDF2 ì‚¬ìš©
        if not text_content.strip():
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
            for page in pdf_reader.pages:
                text_content += page.extract_text() + "\n"
        
        return text_content.strip()
        
    except Exception as e:
        st.error(f"PDF ë°”ì´íŠ¸ ë°ì´í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_from_docx(uploaded_file):
    """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸°
        file_bytes = uploaded_file.read()
        return extract_text_from_docx_bytes(file_bytes)
        
    except Exception as e:
        st.error(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_from_docx_bytes(file_bytes):
    """DOCX ë°”ì´íŠ¸ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ Document ê°ì²´ ìƒì„±
        doc = Document(io.BytesIO(file_bytes))
        text_content = ""
        for paragraph in doc.paragraphs:
            text_content += paragraph.text + "\n"
        return text_content.strip()
        
    except Exception as e:
        st.error(f"DOCX ë°”ì´íŠ¸ ë°ì´í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_from_txt(uploaded_file):
    """TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # íŒŒì¼ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸°
        file_bytes = uploaded_file.read()
        
        # íŒŒì¼ì„ ë¬¸ìì—´ë¡œ ë””ì½”ë”©
        if uploaded_file.encoding:
            text_content = str(file_bytes, uploaded_file.encoding)
        else:
            # ì¸ì½”ë”©ì„ ëª¨ë¥´ëŠ” ê²½ìš° UTF-8ë¡œ ì‹œë„
            text_content = str(file_bytes, 'utf-8')
        
        return text_content.strip()
        
    except Exception as e:
        st.error(f"TXT í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return ""

def extract_text_from_uploaded_file(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ìë™ ì„ íƒ)"""
    file_extension = uploaded_file.name.lower().split('.')[-1]
    
    if file_extension == 'pdf':
        return extract_text_from_pdf(uploaded_file)
    elif file_extension == 'docx':
        return extract_text_from_docx(uploaded_file)
    elif file_extension == 'txt':
        return extract_text_from_txt(uploaded_file)
    else:
        st.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
        return ""
